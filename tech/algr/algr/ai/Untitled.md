# Untitled

ルールベース

コーパスベースMT

neural machine learning

llm

BLEU値20~30

訓練/

translate input-sentence

compare

NMT

EBMT NICT dev

訓練/重複

“Adapt and EMBT” is the best

NICT and Finance-cho of Japan deved.

Toshiba Digital Solutions co.,ltd.

Toppan-printing 

# NMT and LLM

LLM costs! LLM is slow!

Researchers now research LLM mainly.

Kageura prof.

Give competence 

Meta-Llama-3-70B

LLM can use 

Haullcination

RAG

日本特許翻訳npat

自動ポストエディット

LLM

NMT(NICT-Tokkyo-NT)

Problems of NMT

Error of specific terminologies(can be resolved by fine-tuning)

Unkown-words

役抜け原文aymari

- Genbun ayamari
- Inline-tag
- Cannot translate condsidering the context beyond segments
- Cannot Style

LLM: has inteligence

1. Understands instructions
2. Can induce
3. Can translate

NMT intelligence can only do translation and doesn’t have general ability.

Automated post-edit

LLM’s fine-tuning enables domain adaptive MT.

What’s fine-tuning?

To improve the SEINOU of model.

Batch-size

1. データ準備
    1. タスク固有のデータセットの収集
    2. データのクリーニングと前処理
    3. 
2. モデルの選択
    1. 事前学習モデルの
3. ハイパーパラメータの設定
4. 学習プロセス
5. 評価と反復

![image.jpg](Untitled%20106496eb7c90800e90fcfedc03749fae/image.jpg)

ファジーマッチ

few shot

In

MMLU評価に半日かかる。80%で人間専門家なみ

自動ポストエディット

- Future of LLM
    
    Domain adaptive MT using LLM
    
    New model
    
    Combinej
    
    Can translate multiple segments at once
    
    Translate inline-tag precisely