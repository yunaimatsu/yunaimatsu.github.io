# Supervised Learning

- ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®ç¨®é¡ã«ã‚ˆã‚‹åˆ†é¡
    
    éŸ³å£°
    
    éŸ³æ¥½
    
    è¨€èª
    
    ç”»åƒ
    

# Basis

- Terminology
    
    <aside>
    ğŸ’¡
    
    There are many ways how `input` and `output` are called
    
    </aside>
    
    |  | Input | Output |
    | --- | --- | --- |
    | Input or Output | Input variable | Output variable |
    | explanation | Explanatory variable | Explained variable |
    | dependency | Independent variable | Dependent variable |
    | Example/Instance | Training data | Supervision data |
- æ©Ÿæ¢°å­¦ç¿’ä¸€èˆ¬ã§ã€å„å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ãŒæŒã¤featureã«ç€ç›®ã—ã€ãã‚Œã‚‰ã‚’Vectorã®å„æ¬¡å…ƒã«å¯¾å¿œã•ã›ã‚‹æ–¹æ³•ã€‚

Input data are used in the form of vector $\boldsymbol{x}=\mathbb{R}^{d}(d\textrm{ is size of the vector})$ whose elements are real-number value.

The features of the input data correspond to each dimension of the vector.

- Weight vector (Mapping)
    
    

<aside>
ğŸ’¡ æ•™å¸«ã‚ã‚Šå­¦ç¿’ã§ã¯ã€å›å¸°ã¨åˆ†é¡ãŒè¡Œã‚ã‚Œã‚‹ã€‚

</aside>

# Regression

> Output is quantitive
> 

# Classification

> Output is qualificative i.g. class, category, label
> 
> 
> Learn the relation$f:x\longmapsto y$
> 

### Non-structured prediction

Inputã‚’ã€å®Ÿæ•°ãŒè¦ç´ ã®ãƒ™ã‚¯ãƒˆãƒ«ã§è¡¨ç¾ã™ã‚‹ã€‚ç‰¹å¾´é‡è¡¨ç¾

1. binary
    
    ç‰¹å¾´ãƒ™ã‚¯ãƒˆãƒ«ã¨é‡ã¿ãƒ™ã‚¯ãƒˆãƒ«ã®ç©ã®æ­£ä¾‹(Positive example, y=1ã¨åˆ†é¡ã•ã‚Œã‚‹)ãƒ»è² ä¾‹(Negative example, y=0ã¨åˆ†é¡ã•ã‚Œã‚‹)ã§äºŒã¤ã«åˆ†ã‘ã‚‹ã€‚
    
    [Perceptron](Supervised%20Learning%20956457ebb2b54179920238f73d9e9758/Perceptron%200dc1281e02fe4c6893af3947b46e76e4.md)
    
2. multiclass

### Structured prediction

## Training data(Supervision data): collection of case.

$$
\textrm{MSE}=\frac{1}{n}\sum^{n}_{1}(y_{i}-\hat{y_{i}})^{2}=\frac{1}{n}
$$

Case: A pair of Input and Output

$x^{(n)}$ is input while $y^{(n)}$ is output

$$
\mathbb{D}=\{(x^{(1)},y^{(1)}),(x^{(2)},y^{(2)}),...,(x^{(n)},y^{(n)})\}
$$

# Process of  learning

1. Train, Validation, Testã®ä¸‰ã¤ã«ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†ã‘ã‚‹ã€‚
2. Model building
3. Hyperparameter setting
4. Model learning
    1. Forward propagation
    2. Backward propagation

[ã€2022 å¹´ç‰ˆã€‘è‡ªç„¶è¨€èªå‡¦ç†ãƒ»NLP ãŠã™ã™ã‚æ›¸ç± 10 é¸](https://blog.kikagaku.co.jp/book-nlp)

[è‡ªç„¶è¨€èªå‡¦ç†ã¨ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ: AIã«ã‚ˆã‚‹æ–‡ç« ç”Ÿæˆã¨ä¼šè©±ã‚¨ãƒ³ã‚¸ãƒ³é–‹ç™º](https://youtube.com/playlist?list=PLcd5jOpoEDGDFoGndHM1EMYYjQdwDM-JN)

[ã€éŸ³å£°è¨€èªå‡¦ç†ã¨è‡ªç„¶è¨€èªå‡¦ç†ã€](Supervised%20Learning%20956457ebb2b54179920238f73d9e9758/%E3%80%8E%E9%9F%B3%E5%A3%B0%E8%A8%80%E8%AA%9E%E5%87%A6%E7%90%86%E3%81%A8%E8%87%AA%E7%84%B6%E8%A8%80%E8%AA%9E%E5%87%A6%E7%90%86%E3%80%8F%2017acf6bb4260477bb839fca95e53619f.md)

[NLPã¨è¨€èªã‚³ãƒ¼ãƒ‘ã‚¹](Supervised%20Learning%20956457ebb2b54179920238f73d9e9758/NLP%E3%81%A8%E8%A8%80%E8%AA%9E%E3%82%B3%E3%83%BC%E3%83%8F%E3%82%9A%E3%82%B9%20ccebe74694fd468985433f88bb375c33.md)

[NLPã§ä½¿ã†ã‚½ãƒ•ãƒˆä¸€è¦§](Supervised%20Learning%20956457ebb2b54179920238f73d9e9758/NLP%E3%81%A6%E3%82%99%E4%BD%BF%E3%81%86%E3%82%BD%E3%83%95%E3%83%88%E4%B8%80%E8%A6%A7%209465aef09f654a9ba58847e0a749e2c2.md)

[NLP, Corpus](Supervised%20Learning%20956457ebb2b54179920238f73d9e9758/NLP,%20Corpus%20c05466bf6c9e40b5adbf7656bcf7ab85.md)

- ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°
    - ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°ãƒ¢ãƒ‡ãƒ«
        
        $\bm{x}$ãŒ$\hat{y}=1$ã¨ã—ã¦åˆ†é¡ã•ã‚Œã‚‹ç¢ºç‡ã‚’æ±‚ã‚ã‚‹é–¢æ•°ã€‚
        
        ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯